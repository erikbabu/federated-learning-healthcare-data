{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centralised EMNIST solution (benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "%matplotlib inline \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size_train = 128\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "# Other configuration\n",
    "random_seed = 1\n",
    "torch.manual_seed(random_seed) # For model reproducibility\n",
    "use_cuda = False\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to save MNIST train and test data\n",
    "data_path = '../leaf/data/femnist/data/raw_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert images to tensors and normalise (implicitly) in range [0, 1]\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Using updated link for dataset: https://cloudstor.aarnet.edu.au/plus/s/ZNmuFiuQTqZlu9W/download\n",
    "\n",
    "trainset = torchvision.datasets.EMNIST(root=data_path, split='byclass', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size_train,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.EMNIST(root=data_path, split='byclass', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size_test,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = [str(i) for i in range(10)]\n",
    "classes += list(map(chr, range(65, 91)))\n",
    "classes += list(map(chr, range(97, 123)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    3     h     F     0\n"
     ]
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img\n",
    "    \n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)), origin='lower')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[:4]))\n",
    "\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 100)\n",
    "        self.fc3 = nn.Linear(100, 62)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.drop_out = nn.Dropout()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.drop_out(x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.drop_out(x)\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop_out(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.709\n",
      "[1,  4000] loss: 0.989\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'emnist_centralised.pth'\n",
    "torch.save(net.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test network on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images[:4]))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload saved model\n",
    "net = Net().to(device)\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "\n",
    "\n",
    "outputs = net(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(len(classes)))\n",
    "class_total = list(0. for i in range(len(classes)))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(len(predicted)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
