{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocess test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to load test data\n",
    "DATA_BASE_PATH = os.getenv('PROJECT_DATA_BASE_DIR')\n",
    "data_path = os.path.abspath(os.path.join(DATA_BASE_PATH, 'EMNIST'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert images to tensors and normalise (implicitly) in range [0, 1]\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Using updated link for dataset: https://cloudstor.aarnet.edu.au/plus/s/ZNmuFiuQTqZlu9W/download\n",
    "testset = torchvision.datasets.EMNIST(root=data_path, split='byclass', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1000,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = [str(i) for i in range(10)]\n",
    "classes += list(map(chr, range(65, 91)))\n",
    "classes += list(map(chr, range(97, 123)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace the copying of model with just importing it from a python file!\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 100)\n",
    "        self.fc3 = nn.Linear(100, 62)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.drop_out = nn.Dropout()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=100, bias=True)\n",
       "  (fc3): Linear(in_features=100, out_features=62, bias=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'emnist_centralised.pth'\n",
    "\n",
    "net = Net().to(device)\n",
    "\n",
    "checkpoint = torch.load(model_path)\n",
    "net.load_state_dict(checkpoint['model_state_dict'])\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse Overall Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 83 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse Per-Class performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of     0 : 50 %\n",
      "Accuracy of     1 : 96 %\n",
      "Accuracy of     2 : 93 %\n",
      "Accuracy of     3 : 97 %\n",
      "Accuracy of     4 : 96 %\n",
      "Accuracy of     5 : 92 %\n",
      "Accuracy of     6 : 97 %\n",
      "Accuracy of     7 : 98 %\n",
      "Accuracy of     8 : 95 %\n",
      "Accuracy of     9 : 97 %\n",
      "Accuracy of     A : 93 %\n",
      "Accuracy of     B : 85 %\n",
      "Accuracy of     C : 96 %\n",
      "Accuracy of     D : 84 %\n",
      "Accuracy of     E : 89 %\n",
      "Accuracy of     F : 87 %\n",
      "Accuracy of     G : 75 %\n",
      "Accuracy of     H : 85 %\n",
      "Accuracy of     I : 45 %\n",
      "Accuracy of     J : 74 %\n",
      "Accuracy of     K : 28 %\n",
      "Accuracy of     L : 90 %\n",
      "Accuracy of     M : 93 %\n",
      "Accuracy of     N : 97 %\n",
      "Accuracy of     O : 78 %\n",
      "Accuracy of     P : 87 %\n",
      "Accuracy of     Q : 77 %\n",
      "Accuracy of     R : 89 %\n",
      "Accuracy of     S : 86 %\n",
      "Accuracy of     T : 87 %\n",
      "Accuracy of     U : 96 %\n",
      "Accuracy of     V : 74 %\n",
      "Accuracy of     W : 80 %\n",
      "Accuracy of     X : 69 %\n",
      "Accuracy of     Y : 72 %\n",
      "Accuracy of     Z : 53 %\n",
      "Accuracy of     a : 88 %\n",
      "Accuracy of     b : 79 %\n",
      "Accuracy of     c :  0 %\n",
      "Accuracy of     d : 94 %\n",
      "Accuracy of     e : 93 %\n",
      "Accuracy of     f :  9 %\n",
      "Accuracy of     g : 38 %\n",
      "Accuracy of     h : 92 %\n",
      "Accuracy of     i : 34 %\n",
      "Accuracy of     j : 66 %\n",
      "Accuracy of     k : 80 %\n",
      "Accuracy of     l :  0 %\n",
      "Accuracy of     m :  1 %\n",
      "Accuracy of     n : 93 %\n",
      "Accuracy of     o :  0 %\n",
      "Accuracy of     p : 36 %\n",
      "Accuracy of     q : 20 %\n",
      "Accuracy of     r : 94 %\n",
      "Accuracy of     s :  0 %\n",
      "Accuracy of     t : 95 %\n",
      "Accuracy of     u :  0 %\n",
      "Accuracy of     v : 20 %\n",
      "Accuracy of     w : 59 %\n",
      "Accuracy of     x : 61 %\n",
      "Accuracy of     y : 28 %\n",
      "Accuracy of     z : 61 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(len(classes)))\n",
    "class_total = list(0. for i in range(len(classes)))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(len(predicted)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
